{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Rediscover the Higgs boson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot as uproot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import vector\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Access a the data file and convert into a 'pandas dataframe'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eventsData = uproot.open(\"data_Skim_GamGam.root\")[\"mini\"]\n",
    "df = eventsData.arrays([\"photon_pt\", \"photon_eta\", \"photon_phi\", \"photon_E\",  \"diphoton_mass\"], library=\"pd\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " NOTE - NONE OF THE REST OF THIS NOTEBOOK WILL RUN UNTIL YOU DOWNLOAD THE INPUT DATA AND SIMULATION FILES FROM HERE. \n",
    "\n",
    " - https://uctcloud-my.sharepoint.com/:f:/g/personal/01466689_wf_uct_ac_za/En-_dYktEINOu3XP2z3VDK8B3NCT_Wj7shIBVCcV72SkAg?e=cu1Ldy\n",
    "\n",
    " - PLACE ALL FILES IN THE SAME DIRECTORY AS THIS NOTEBOOK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Apply a series of event selections\n",
    "    - only select events containing two photons with specific pt and eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuts0 = df[(df['photon_pt'].apply(lambda x: x[0]) > 35000) & (df['photon_pt'].apply(lambda x: x[1]) > 25000)]\n",
    "\n",
    "cuts1 = cuts0[(np.abs(cuts0['photon_eta'].apply(lambda x: x[0])) < 2.37) & (np.abs(cuts0['photon_eta'].apply(lambda x: x[1])) < 2.37)]\n",
    "\n",
    "# Alternative eta cut, selects central photons only\n",
    "# cuts1 = cuts0[(np.abs(cuts0['photon_eta'].apply(lambda x: x[0])) < 0.75) & (np.abs(cuts0['photon_eta'].apply(lambda x: x[1])) < 0.75)]\n",
    "\n",
    "# These cuts exclude a small region of the ATLAS detector known to have poor efficiency and resolution.\n",
    "cuts1a = cuts1[(np.abs(cuts1['photon_eta'].apply(lambda x: x[0])) < 1.37) | (np.abs(cuts1['photon_eta'].apply(lambda x: x[0])) > 1.52)]\n",
    "cuts1b = cuts1a[(np.abs(cuts1a['photon_eta'].apply(lambda x: x[1])) < 1.37) | (np.abs(cuts1a['photon_eta'].apply(lambda x: x[1])) > 1.52)]\n",
    "\n",
    "# Here we apply kinematic criteria that removes diphotons that are just random combinations\n",
    "cuts2a = cuts1b[(cuts1b['photon_pt'].apply(lambda x: x[0]) / cuts1b['diphoton_mass']) > 0.35]\n",
    "cuts2b = cuts2a[(cuts2a['photon_pt'].apply(lambda x: x[1]) / cuts2a['diphoton_mass']) > 0.25]\n",
    "\n",
    "# finally we only look in the diphoton mass regions close to the known higgs mass\n",
    "cuts3 = cuts2b[(cuts2b['diphoton_mass'].apply(lambda x: x)) > 105000.0]\n",
    "\n",
    "finalData = cuts3\n",
    "\n",
    "print(\"Number of selected events = \" + str(len(finalData.index)))\n",
    "finalData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. Combine the four vectors of the photons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we make arrays of four-vectors for the muons. we make separate arrays for leading and sub-leading muons\n",
    "pt0 = finalData['photon_pt'].apply(lambda x: x[0]).to_numpy()\n",
    "eta0 = finalData['photon_eta'].apply(lambda x: x[0]).to_numpy()\n",
    "phi0 = finalData['photon_phi'].apply(lambda x: x[0]).to_numpy()\n",
    "E0 = finalData['photon_E'].apply(lambda x: x[0]).to_numpy()\n",
    "\n",
    "pt1 = finalData['photon_pt'].apply(lambda x: x[1]).to_numpy()\n",
    "eta1 = finalData['photon_eta'].apply(lambda x: x[1]).to_numpy()\n",
    "phi1 = finalData['photon_phi'].apply(lambda x: x[1]).to_numpy()\n",
    "E1 = finalData['photon_E'].apply(lambda x: x[1]).to_numpy()\n",
    "\n",
    "lvArray0 = vector.array(\n",
    "    {\n",
    "        \"pt\": pt0,\n",
    "        \"phi\": phi0,\n",
    "        \"eta\": eta0,\n",
    "        \"E\": E0,\n",
    "    }\n",
    ")\n",
    "\n",
    "lvArray1 = vector.array(\n",
    "    {\n",
    "        \"pt\": pt1,\n",
    "        \"phi\": phi1,\n",
    "        \"eta\": eta1,\n",
    "        \"E\": E1,\n",
    "    }\n",
    ")\n",
    "\n",
    "lvArray = lvArray0 + lvArray1\n",
    "lvArray\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4. Create a histogram of the masses of the diphoton system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mH = 124894.0\n",
    "sigmaH = 210.0\n",
    "\n",
    "#example binning\n",
    "nBins = 30\n",
    "minMass = 105000\n",
    "maxMass = 160000\n",
    "\n",
    "countsData, edges = np.histogram(lvArray.mass, bins=nBins, range=(minMass,maxMass))\n",
    "\n",
    "#create an array of the centre of each bin, useful for plotting the pdf later\n",
    "centres = (edges[1:] + edges[:-1]) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5. Fit a background model to data and make a comparison plot.\n",
    "\n",
    "- create a statistical model for the diphoton mass distribution composed of of a gaussian ('norm') pdf for the $H\\rightarrow \\gamma \\gamma$ process and a third-order polynomial fuction for the background diphoton processes. The mean of the signal gauusian distribution is chosen as the measured $m_{H}$ value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.poly1d(np.polyfit(centres, countsData, 3))\n",
    "\n",
    "#guess a signal integral for illustration purposes\n",
    "integral = 10113802.23\n",
    "\n",
    "s = ( scipy.stats.norm.pdf(centres, mH, sigmaH) * integral)\n",
    "sb = s+b(centres)\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"$ m_{\\gamma\\gamma}$\")\n",
    "plt.ylabel(\"events per bin\")\n",
    "plt.plot(centres, s, 'b', linewidth=1, label=\"Potential Signal\")\n",
    "plt.plot(centres, b(centres), 'k', linewidth=1, linestyle=\"--\", label=\"Background\")\n",
    "plt.plot(centres, sb, 'r', linewidth=2, label=\"Signal+Background\")\n",
    "\n",
    "plt.errorbar(centres, countsData, yerr=np.sqrt(countsData), fmt='o', mfc='k', mec='k',ms=4, mew=0.2, ecolor='k',label=\"ATLAS Open Data\",)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6. Create a plot of the binned \"residuals\" vs $m_{H}$\n",
    "\n",
    "- Subtract the polynomial background prediction from the data to calculate the $\\emph{residuals}$. \n",
    "- The residual in each bin is our estimate of the signal in that bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#ratio plot \n",
    "residuals = countsData - b(centres) \n",
    "plt.figure()\n",
    "plt.xlabel(\"$ m_{\\gamma\\gamma}$\")\n",
    "plt.ylabel(\"Data - background\")\n",
    "plt.errorbar(centres, residuals, yerr=np.sqrt(countsData), label=\"Estimated Signal (Data - background)\", fmt='o', mfc='k', mec='k', mew=0.2, ecolor='k')\n",
    "\n",
    "nSteps = 100\n",
    "\n",
    "plt.plot(centres, s, 'b', linewidth=1, label=\"Potential signal\")\n",
    "plt.plot(centres, np.zeros(len(centres)), 'k', linewidth=1, linestyle=\"--\", label=\"Background\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7.  Simultaneously fit  $m_{H}$, $\\Gamma_{H}$ and $N_{H\\rightarrow\\gamma\\gamma}$ from the residuals\n",
    "- If we assume the signal will have a gaussian shape with $\\mu \\approx m_{H} \\approx$ 125000 MeV, we can use python libraries to fit a gaussian distrubution to the residual graph and estimate the number of signal events $N_{H\\rightarrow\\gamma\\gamma}$ in the data as well as $m_{H}$ and $\\Gamma_{H}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assume mass, sigma\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def gaussian(x, mean, amplitude, standard_deviation):\n",
    "    return amplitude * np.exp( - ((x - mean) / standard_deviation) ** 2)\n",
    "\n",
    "bestFitParams, covarianceMatrix = curve_fit(gaussian, centres, residuals, p0=[125000., 200., 1000.])\n",
    "\n",
    "#the p0 values are that the 'starting points' for ùëöùêª, Œìùêª and ùëÅùêª‚Üíùõæùõæ in the fit.\n",
    "\n",
    "x_interval_for_fit = np.linspace(edges[0], edges[-1], 10000)\n",
    "plt.plot(x_interval_for_fit, gaussian(x_interval_for_fit, *bestFitParams), label='$ H \\gamma \\gamma$ signal')\n",
    "plt.errorbar(centres, residuals, yerr=np.sqrt(countsData), label=\"Data - Background\", fmt='o', mfc='k', mec='k', mew=0.2, ecolor='k')\n",
    "plt.legend()\n",
    "plt.xlabel(\"$ m_{\\gamma\\gamma}$\")\n",
    "plt.ylabel(\"Data - prediction\")\n",
    "\n",
    "# add the values of thr fitted signal shape at a series of points to estimate the total \n",
    "# number of signal events\n",
    "limA = 11500\n",
    "limA = 13500\n",
    "sigIntegral = 0.0\n",
    "stepSize = (maxMass - minMass)/(nSteps)\n",
    "\n",
    "xStep = minMass\n",
    "\n",
    "for p in range(0, nSteps):\n",
    "        xStep = xStep + stepSize\n",
    "        sigHeight = gaussian(xStep, *bestFitParams)\n",
    "        #print(sigHeight)\n",
    "        sigIntegral = (sigIntegral + (sigHeight) )\n",
    "\n",
    "print(\"best fitting parameters:\")\n",
    "print(\"MH = \" + str(float(bestFitParams[0])))\n",
    "print(\"sigmaH = \" + str(float(bestFitParams[1]) ))\n",
    "print(\"NH = \" + str(float(sigIntegral) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8  Estimate the statistical significance of the $H\\rightarrow \\gamma \\gamma$ signal.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code goes here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9 - Your turn!\n",
    "\n",
    "It's time for you to try improvements to the analysis especially if they can improve the significance of the signal.\n",
    "Refer to the lab manual for suggested modifications.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
